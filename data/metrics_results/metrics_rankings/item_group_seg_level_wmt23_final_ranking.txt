lang:                                     en-de     en-de     he-en     he-en     zh-en     zh-en
level:                                      seg       seg       seg       seg       seg       seg
corr_fcn:                               pearson     acc-t   pearson     acc-t   pearson     acc-t
metric                       avg-corr     task1     task2     task3     task4     task5     task6
---------------------------  --------  --------  --------  --------  --------  --------  --------
XCOMET-Ensemble               1 0.659   2 0.538   1 0.604   1 0.479   1 0.586   3 0.421   1 0.543
mbr-metricx-qe[noref]         2 0.648   1 0.543   5 0.584   2 0.448   6 0.553   1 0.436   2 0.537
MetricX-23                    3 0.645   5 0.507   2 0.603   3 0.441   2 0.577   6 0.373   4 0.531
GEMBA-MQM[noref]              4 0.639  10 0.482   9 0.572   5 0.431   4 0.564   2 0.434   7 0.522
XCOMET-QE-Ensemble[noref]     5 0.636   6 0.507   4 0.588  11 0.397   5 0.554   5 0.380   3 0.533
MetricX-23-QE[noref]          6 0.636   3 0.511   3 0.596  13 0.387   3 0.564  10 0.359   5 0.527
_COMET                        7 0.628   4 0.508   7 0.574   7 0.421  10 0.532   9 0.364  11 0.514
_CometKiwi[noref]             8 0.625  12 0.463  10 0.569  16 0.375   8 0.544   4 0.388   6 0.525
_BLEURT-20                    9 0.625   8 0.492   8 0.572   8 0.418  14 0.519   7 0.371   8 0.518
KG-BERTScore[noref]          10 0.618  14 0.456  14 0.556  15 0.375   9 0.537   8 0.369   9 0.516
cometoid22-wmt22[noref]      11 0.615   7 0.499   6 0.578  23 0.309  15 0.515  11 0.357  10 0.515
_YiSi-1                      12 0.610  18 0.404  18 0.542   4 0.439  11 0.529  15 0.329  12 0.504
_docWMT22CometDA             13 0.607   9 0.484  13 0.559  14 0.379  20 0.497  16 0.327  18 0.493
sescoreX                     14 0.602  13 0.459  11 0.563  18 0.370  22 0.484  21 0.295  14 0.499
_prismRef                    15 0.601  25 0.349  29 0.518   6 0.428  12 0.528  14 0.332  13 0.504
Calibri-COMET22              16 0.601  11 0.477  25 0.522  12 0.397  16 0.515  18 0.311  27 0.474
_BERTscore                   17 0.597  24 0.355  22 0.528   9 0.412  17 0.515  19 0.309  15 0.499
_docWMT22CometKiwiDA[noref]  18 0.596  16 0.426  16 0.547  20 0.324  21 0.489  13 0.340  17 0.493
MaTESe                       19 0.595  29 0.330  21 0.528  17 0.373   7 0.550  17 0.325  25 0.479
Calibri-COMET22-QE[noref]    20 0.592  15 0.432  32 0.483  19 0.354  18 0.506  12 0.355  19 0.491
mre-score-labse-regular      21 0.592  21 0.376  19 0.530  10 0.407  13 0.522  24 0.251  22 0.481
_MS-COMET-QE-22[noref]       22 0.587  19 0.400  17 0.546  29 0.252  19 0.498  20 0.306  16 0.498
XLsim                        23 0.571  22 0.372  23 0.527  21 0.314  24 0.480  28 0.218  31 0.464
tokengram_F                  24 0.570  27 0.340  26 0.520  22 0.311  26 0.461  23 0.262  21 0.485
_chrF                        25 0.570  28 0.336  28 0.519  24 0.308  27 0.460  22 0.263  20 0.485
SENTINEL-CAND-DA[noref]      26 0.567  17 0.406  15 0.551  31 0.168  25 0.474  29 0.215  23 0.480
MEE4                         27 0.566  23 0.360  20 0.529  25 0.291  32 0.441  25 0.236  24 0.480
_f200spBLEU                  28 0.562  26 0.343  24 0.526  26 0.287  28 0.447  26 0.220  26 0.476
SENTINEL-CAND-MQM[noref]     29 0.561  20 0.396  12 0.562  32 0.104  23 0.483  31 0.201  28 0.473
eBLEU                        30 0.556  30 0.317  30 0.512  27 0.280  29 0.445  27 0.219  29 0.473
_BLEU                        31 0.554  31 0.310  27 0.520  28 0.260  30 0.442  30 0.208  30 0.472
embed_llama                  32 0.524  32 0.242  31 0.483  30 0.188  33 0.430  32 0.138  32 0.447
_prismSrc[noref]             33 0.488  34 0.102  33 0.426  33 0.100  31 0.441  33 0.078  33 0.421
_Random-sysname[noref]       34 0.470  33 0.124  34 0.409  34 0.057  34 0.428  34 0.019  34 0.381
SENTINEL-REF-DA              35 0.400  35 0.000  35 0.231  35 0.000  35 0.428  35 0.000  35 0.240
SENTINEL-REF-MQM             36 0.400  36 0.000  36 0.231  36 0.000  36 0.428  36 0.000  36 0.240
SENTINEL-SRC-DA[noref]       37 0.400  37 0.000  37 0.231  37 0.000  37 0.428  37 0.000  37 0.240
SENTINEL-SRC-MQM[noref]      38 0.400  38 0.000  38 0.231  38 0.000  38 0.428  38 0.000  38 0.240





\begin{tabular}{l|rr|rr|rr|rr|rr|rr|rr}
\toprule
lang: & \multicolumn{2}{|l}{} & \multicolumn{2}{|l}{en-de} & \multicolumn{2}{|l}{en-de} & \multicolumn{2}{|l}{he-en} & \multicolumn{2}{|l}{he-en} & \multicolumn{2}{|l}{zh-en} & \multicolumn{2}{|l}{zh-en} \\
level: & \multicolumn{2}{|l}{} & \multicolumn{2}{|l}{seg} & \multicolumn{2}{|l}{seg} & \multicolumn{2}{|l}{seg} & \multicolumn{2}{|l}{seg} & \multicolumn{2}{|l}{seg} & \multicolumn{2}{|l}{seg} \\
corr\_fcn: & \multicolumn{2}{|l}{} & \multicolumn{2}{|l}{pearson} & \multicolumn{2}{|l}{acc-t} & \multicolumn{2}{|l}{pearson} & \multicolumn{2}{|l}{acc-t} & \multicolumn{2}{|l}{pearson} & \multicolumn{2}{|l}{acc-t} \\
metric & \multicolumn{2}{|l}{avg-corr} & \multicolumn{2}{|l}{task1} & \multicolumn{2}{|l}{task2} & \multicolumn{2}{|l}{task3} & \multicolumn{2}{|l}{task4} & \multicolumn{2}{|l}{task5} & \multicolumn{2}{|l}{task6} \\
\midrule
XCOMET-Ensemble & \textbf{1} & \textbf{0.659} & 2 & 0.538 & \textbf{1} & \textbf{0.604} & \textbf{1} & \textbf{0.479} & \textbf{1} & \textbf{0.586} & 3 & 0.421 & \textbf{1} & \textbf{0.543} \\
mbr-metricx-qe* & 2 & 0.648 & \textbf{1} & \textbf{0.543} & 5 & 0.584 & 2 & 0.448 & 6 & 0.553 & \textbf{1} & \textbf{0.436} & 2 & 0.537 \\
MetricX-23 & 3 & 0.645 & 5 & 0.507 & 2 & 0.603 & 3 & 0.441 & 2 & 0.577 & 6 & 0.373 & 4 & 0.531 \\
GEMBA-MQM* & 4 & 0.639 & 10 & 0.482 & 9 & 0.572 & 5 & 0.431 & 4 & 0.564 & 2 & 0.434 & 7 & 0.522 \\
XCOMET-QE-Ensemble* & 5 & 0.636 & 6 & 0.507 & 4 & 0.588 & 11 & 0.397 & 5 & 0.554 & 5 & 0.380 & 3 & 0.533 \\
MetricX-23-QE* & 6 & 0.636 & 3 & 0.511 & 3 & 0.596 & 13 & 0.387 & 3 & 0.564 & 10 & 0.359 & 5 & 0.527 \\
\underline{COMET} & 7 & 0.628 & 4 & 0.508 & 7 & 0.574 & 7 & 0.421 & 10 & 0.532 & 9 & 0.364 & 11 & 0.514 \\
\underline{CometKiwi}* & 8 & 0.625 & 12 & 0.463 & 10 & 0.569 & 16 & 0.375 & 8 & 0.544 & 4 & 0.388 & 6 & 0.525 \\
\underline{BLEURT-20} & 9 & 0.625 & 8 & 0.492 & 8 & 0.572 & 8 & 0.418 & 14 & 0.519 & 7 & 0.371 & 8 & 0.518 \\
KG-BERTScore* & 10 & 0.618 & 14 & 0.456 & 14 & 0.556 & 15 & 0.375 & 9 & 0.537 & 8 & 0.369 & 9 & 0.516 \\
cometoid22-wmt22* & 11 & 0.615 & 7 & 0.499 & 6 & 0.578 & 23 & 0.309 & 15 & 0.515 & 11 & 0.357 & 10 & 0.515 \\
\underline{YiSi-1} & 12 & 0.610 & 18 & 0.404 & 18 & 0.542 & 4 & 0.439 & 11 & 0.529 & 15 & 0.329 & 12 & 0.504 \\
\underline{docWMT22CometDA} & 13 & 0.607 & 9 & 0.484 & 13 & 0.559 & 14 & 0.379 & 20 & 0.497 & 16 & 0.327 & 18 & 0.493 \\
sescoreX & 14 & 0.602 & 13 & 0.459 & 11 & 0.563 & 18 & 0.370 & 22 & 0.484 & 21 & 0.295 & 14 & 0.499 \\
\underline{prismRef} & 15 & 0.601 & 25 & 0.349 & 29 & 0.518 & 6 & 0.428 & 12 & 0.528 & 14 & 0.332 & 13 & 0.504 \\
Calibri-COMET22 & 16 & 0.601 & 11 & 0.477 & 25 & 0.522 & 12 & 0.397 & 16 & 0.515 & 18 & 0.311 & 27 & 0.474 \\
\underline{BERTscore} & 17 & 0.597 & 24 & 0.355 & 22 & 0.528 & 9 & 0.412 & 17 & 0.515 & 19 & 0.309 & 15 & 0.499 \\
\underline{docWMT22CometKiwiDA}* & 18 & 0.596 & 16 & 0.426 & 16 & 0.547 & 20 & 0.324 & 21 & 0.489 & 13 & 0.340 & 17 & 0.493 \\
MaTESe & 19 & 0.595 & 29 & 0.330 & 21 & 0.528 & 17 & 0.373 & 7 & 0.550 & 17 & 0.325 & 25 & 0.479 \\
Calibri-COMET22-QE* & 20 & 0.592 & 15 & 0.432 & 32 & 0.483 & 19 & 0.354 & 18 & 0.506 & 12 & 0.355 & 19 & 0.491 \\
mre-score-labse-regular & 21 & 0.592 & 21 & 0.376 & 19 & 0.530 & 10 & 0.407 & 13 & 0.522 & 24 & 0.251 & 22 & 0.481 \\
\underline{MS-COMET-QE-22}* & 22 & 0.587 & 19 & 0.400 & 17 & 0.546 & 29 & 0.252 & 19 & 0.498 & 20 & 0.306 & 16 & 0.498 \\
XLsim & 23 & 0.571 & 22 & 0.372 & 23 & 0.527 & 21 & 0.314 & 24 & 0.480 & 28 & 0.218 & 31 & 0.464 \\
tokengram\_F & 24 & 0.570 & 27 & 0.340 & 26 & 0.520 & 22 & 0.311 & 26 & 0.461 & 23 & 0.262 & 21 & 0.485 \\
\underline{chrF} & 25 & 0.570 & 28 & 0.336 & 28 & 0.519 & 24 & 0.308 & 27 & 0.460 & 22 & 0.263 & 20 & 0.485 \\
SENTINEL-CAND-DA* & 26 & 0.567 & 17 & 0.406 & 15 & 0.551 & 31 & 0.168 & 25 & 0.474 & 29 & 0.215 & 23 & 0.480 \\
MEE4 & 27 & 0.566 & 23 & 0.360 & 20 & 0.529 & 25 & 0.291 & 32 & 0.441 & 25 & 0.236 & 24 & 0.480 \\
\underline{f200spBLEU} & 28 & 0.562 & 26 & 0.343 & 24 & 0.526 & 26 & 0.287 & 28 & 0.447 & 26 & 0.220 & 26 & 0.476 \\
SENTINEL-CAND-MQM* & 29 & 0.561 & 20 & 0.396 & 12 & 0.562 & 32 & 0.104 & 23 & 0.483 & 31 & 0.201 & 28 & 0.473 \\
eBLEU & 30 & 0.556 & 30 & 0.317 & 30 & 0.512 & 27 & 0.280 & 29 & 0.445 & 27 & 0.219 & 29 & 0.473 \\
\underline{BLEU} & 31 & 0.554 & 31 & 0.310 & 27 & 0.520 & 28 & 0.260 & 30 & 0.442 & 30 & 0.208 & 30 & 0.472 \\
embed\_llama & 32 & 0.524 & 32 & 0.242 & 31 & 0.483 & 30 & 0.188 & 33 & 0.430 & 32 & 0.138 & 32 & 0.447 \\
\underline{prismSrc}* & 33 & 0.488 & 34 & 0.102 & 33 & 0.426 & 33 & 0.100 & 31 & 0.441 & 33 & 0.078 & 33 & 0.421 \\
\underline{Random-sysname}* & 34 & 0.470 & 33 & 0.124 & 34 & 0.409 & 34 & 0.057 & 34 & 0.428 & 34 & 0.019 & 34 & 0.381 \\
SENTINEL-REF-DA & 35 & 0.400 & 35 & 0.000 & 35 & 0.231 & 35 & 0.000 & 35 & 0.428 & 35 & 0.000 & 35 & 0.240 \\
SENTINEL-REF-MQM & 36 & 0.400 & 36 & 0.000 & 36 & 0.231 & 36 & 0.000 & 36 & 0.428 & 36 & 0.000 & 36 & 0.240 \\
SENTINEL-SRC-DA* & 37 & 0.400 & 37 & 0.000 & 37 & 0.231 & 37 & 0.000 & 37 & 0.428 & 37 & 0.000 & 37 & 0.240 \\
SENTINEL-SRC-MQM* & 38 & 0.400 & 38 & 0.000 & 38 & 0.231 & 38 & 0.000 & 38 & 0.428 & 38 & 0.000 & 38 & 0.240 \\
\bottomrule
\end{tabular}

